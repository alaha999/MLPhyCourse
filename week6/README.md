# MLCourse: Week6

We will look at a few examples of Unsupervised Learning methods in this week. So far, we have seen a bunch of Supervised machine learning(ML) methods such as DNN, CNN deploying for Regression or classification tasks. These algorithms need true label of the objects that are there in dataset for classification task.

There is another genre of machine learing methods which goes as Unsupervised ML. They learn from the dataset without any true labels. These algorithms are capable of finding structure or hidden patterns in any dataset.

In today's session we will learn about,

- <mark>KMeans clustering algorithm</mark>
  - Apply this to the standard IRIS Dataset (from sklearn library).

- <mark>DBSCAN clustering algorithm</mark>
  - Apply this algorithm and KMeans on a Particle Physics problem to find cluster of particles and benchmark their performances

- <mark>Dimension Reduction Algorithms(PCA and UMAP)</mark>
  - Do we need multiple features to solve a classification task?
  - How are they helpful?
  - Can we compress the multiple features to a few features(Latent space or low dimensional space)? and check how objects from same class distributes themselves in this low dimensional space?
  - We will apply PCA and UMAP algorithms to the WZ vs ZZ classification task from week4 and benchmarks this algorithms


# Notebooks and Input Files
 This folder has,

- input/week6.txt: Input file for the particle clustering problem
- KMeans_IrisDataset.ipynb
- HEP_ParticlesHitProblem_KMeans_DBSCAN_notebook.ipynb
- PCA_UMAP_DimReductionNotebook.ipynb
- LectureSlides
- README.md


Please follow the lecture slides for more details and homework!













