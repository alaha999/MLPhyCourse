{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Classification Task\n",
    "\n",
    "In this exercise, we will develop a neural network based classification method to discriminate between WZ and ZZ process.\n",
    "WZ and ZZ are standard model processes which can be produced at the proton-proton collision at LHC, CERN.\n",
    "\n",
    "- WZ: W-boson with a Z-boson is produced\n",
    "- ZZ: Two Z boson is produced\n",
    "\n",
    "As we know these bosons have very short lifetime, they decay into other lighter particles such as leptons, quarks(jets) etc.\n",
    "\n",
    "For today we consider they decay in the following way,\n",
    "- WZ $\\rightarrow lll\\nu$\n",
    "- ZZ $\\rightarrow llll$\n",
    "where l stands for light leptons which includes electron($e$) and muon($\\mu$).\n",
    "\n",
    "We look at properties of the decay products, and try to distinguish WZ from ZZ. You have been given input files with some such properties to use as input variables.\n",
    "\n",
    "Follow today's lecture slides to learn about the variables and the set up in details.\n",
    "\n",
    "## Structure of the notebook\n",
    "\n",
    "- The problem is broken down in multiple short tasks and related codeblocks.\n",
    "- We provide instructions for each task. \n",
    "- We expect you to finish the codeblocks and get the result.\n",
    "\n",
    "**Let's start!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "- Import all the necessary libraries (numpy, pandas, .. etc)\n",
    "- dont forget train_test_split, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Give some output name for your file with plots, eg. output.pdf\n",
    "outputname = ''\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "pp = PdfPages(outputname)\n",
    "\n",
    "\n",
    "## Complete this block\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "- Read in some number of variables from the input files\n",
    "- input files are   **input_WZ.txt , input_ZZ.txt** \n",
    "- Look at the companion file ```hep_classify_plot_variables.py```\n",
    "- for a list of variables and their names \n",
    "- Make dataframe for WZ and ZZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names=\n",
    "cols=\n",
    "\n",
    "# Read in the two dataframes, one for WZ and one for ZZ\n",
    "\n",
    "WZBk =\n",
    "ZZBk =\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "\n",
    "- Assign target labels for WZ and ZZ, one is 0, other is 1\n",
    "- This is done by adding one additional column to each dataframe with that specific value\n",
    "- Merge the two dataframes into one for training\n",
    "- Split the label column as y, and the input variables as X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WZBk['label']=\n",
    "ZZBk['label']=\n",
    "\n",
    "# Merge the two dataframes into one for training\n",
    "data = pd.concat([WZBk,ZZBk])\n",
    "\n",
    "\n",
    "# Split the label column as y, and the input variables as X\n",
    "X =\n",
    "y =\n",
    "print(f'Shapes of data, X, y are {data.shape}, {X.shape} , {y.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "- Now we normalize the input variables to all go from -1.0 to 1.0\n",
    "\n",
    "- Now we split the data into a training and a testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxValues = X.max(axis=0)\n",
    "minValues = X.min(axis=0)\n",
    "MaxMinusMin = X.max(axis=0) - X.min(axis=0)\n",
    "normedX = 2*((X-X.min(axis=0))/(MaxMinusMin)) -1.0\n",
    "X = normedX\n",
    "\n",
    "# print the information\n",
    "print(\"Max values\")\n",
    "print(maxValues)\n",
    "print(\"Min values\")\n",
    "print(minValues)\n",
    "\n",
    "\n",
    "# Now we split the data into a training and a testing set\n",
    "X_train, X_test, y_train, y_test =\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "n_features = X_train.shape[1]\n",
    "print(f'The number of input variables is {n_features}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5\n",
    "- Declare your model\n",
    "- compile the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add( )\n",
    "model.add( )\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6\n",
    "- Train the model\n",
    "- Print model summary and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using model.fit\n",
    "history =\n",
    "\n",
    "# Print model summary and save the model\n",
    "model.summary()\n",
    "model.save( ... )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<mark>Phew !! Welldone folks! It's time for plotting!</mark>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7\n",
    "\n",
    "Now make various plots\n",
    "- First plot  accuracy using  history object\n",
    "- plot both accuracy and val_accuracy\n",
    "- Then plot loss using both loss and val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy\n",
    "\n",
    "# plot both accuracy and val accuracy\n",
    "\n",
    "# plot both loss and val loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 8\n",
    "\n",
    "Predict NN Score \n",
    "\n",
    "- plot nn score\n",
    "- plot ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup some new dataframes  t_df is testing, v_df is training (or validation)\n",
    "t_df = pd.DataFrame()\n",
    "v_df = pd.DataFrame()\n",
    "t_df['train_truth'] = y_train\n",
    "t_df['train_prob'] = 0\n",
    "v_df['test_truth'] = y_test\n",
    "v_df['test_prob'] = 0\n",
    "\n",
    "# Now we evaluate the model on the test and train data by calling the\n",
    "# predict function\n",
    "\n",
    "val_pred_proba = model.predict(-------)\n",
    "train_pred_proba = model.predict(------)\n",
    "t_df['train_prob'] = train_pred_proba\n",
    "v_df['test_prob'] = val_pred_proba\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting nn score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mybins = np.arange(0,1.05,0.05)\n",
    "\n",
    "# First we make histograms to plot the testing data as points with errors\n",
    "testsig = plt.hist(v_df[v_df['test_truth']==1]['test_prob'],bins=mybins)\n",
    "testsige = np.sqrt(testsig[0])\n",
    "testbkg = plt.hist(v_df[v_df['test_truth']==0]['test_prob'],bins=mybins)\n",
    "testbkge = np.sqrt(testbkg[0])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.errorbar(testsig[1][1:]-0.025, testsig[0], yerr=testsige, fmt='.', color=\"xkcd:green\",label=\"Test ZZ\", markersize='10')\n",
    "plt.errorbar(testbkg[1][1:]-0.025, testbkg[0], yerr=testbkge, fmt='.', color=\"xkcd:denim\",label=\"Test WZ\", markersize='10')\n",
    "plt.hist(t_df[t_df['train_truth']==1]['train_prob'],bins=mybins, histtype='step', label=\"Train ZZ\", linewidth=3, color='xkcd:greenish',density=False,log=False)\n",
    "plt.hist(t_df[t_df['train_truth']==0]['train_prob'],bins=mybins, histtype='step', label=\"Train WZ\", linewidth=3, color='xkcd:sky blue',density=False,log=False)\n",
    "plt.legend(loc='upper center')\n",
    "plt.xlabel('Score',fontsize=20)\n",
    "plt.ylabel('Events',fontsize=20)\n",
    "plt.title(f'NN Output',fontsize=20)\n",
    "plt.xticks([0.0,0.2,0.4,0.6,0.8,1.0],fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "#plt.savefig('NNscore.png')\n",
    "plt.savefig(pp,format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Now you add code to plot the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " pp.close()\n",
    " print('All done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Good Job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
